services:
  # Database service for data warehouse
  postgresql:
    build:
      context: ./setup/dbt
      dockerfile: Dockerfile
    container_name: postgresql
    environment:
      - JDBC_HOST=${JDBC_HOST}
      - JDBC_PORT=${JDBC_PORT}
      - POSTGRESQL_USER=${JDBC_USER}
      - POSTGRESQL_PASSWORD=${JDBC_PASSWORD}
      - POSTGRESQL_DATABASE=${JDBC_DB}
    ports:
      - '5432:5432'
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./data:/data
      - ./scripts/dbt:/opt/dbt
    networks:
      - data-network

  # Spark master mode
  spark-master:
    build:
      context: ./setup/spark
      dockerfile: Dockerfile
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - JDBC_HOST=${JDBC_HOST}
      - JDBC_PORT=${JDBC_PORT}
      - JDBC_DB=${JDBC_DB}
      - JDBC_USER=${JDBC_USER}
      - JDBC_PASSWORD=${JDBC_PASSWORD}
    ports:
      - '8080:8080'
      - '7077:7077'
    volumes:
      - ./data:/opt/data
      - ./utils:/opt/utils
      - ./scripts/spark:/opt/spark/work
    networks:
      - data-network

  # Spark worker mode
  spark-worker:
    image: 'bitnami/spark:latest'
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2                   # Cores per worker
      - SPARK_WORKER_MEMORY=3g                 # Memory per worker
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2.0'
          memory: 3g
    depends_on:
      - spark-master
    volumes:
      - ./data:/opt/data
      - ./scripts/spark:/opt/spark/work
    networks:
      - data-network

networks:
  data-network:
    driver: bridge

volumes:
  postgres_data:
